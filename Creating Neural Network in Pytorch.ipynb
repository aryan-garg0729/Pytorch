{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "694d4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "62ba93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "cdad571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0         0.0      0.0      5.0     13.0      9.0      1.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0     12.0     13.0      5.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      4.0     15.0     12.0      0.0      0.0   \n",
       "3         0.0      0.0      7.0     15.0     13.0      1.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      1.0     11.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1792      0.0      0.0      4.0     10.0     13.0      6.0      0.0      0.0   \n",
       "1793      0.0      0.0      6.0     16.0     13.0     11.0      1.0      0.0   \n",
       "1794      0.0      0.0      1.0     11.0     15.0      1.0      0.0      0.0   \n",
       "1795      0.0      0.0      2.0     10.0      7.0      0.0      0.0      0.0   \n",
       "1796      0.0      0.0     10.0     14.0      8.0      1.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_55  pixel_56  pixel_57  pixel_58  pixel_59  \\\n",
       "0         0.0      0.0  ...       0.0       0.0       0.0       6.0      13.0   \n",
       "1         0.0      0.0  ...       0.0       0.0       0.0       0.0      11.0   \n",
       "2         0.0      0.0  ...       0.0       0.0       0.0       0.0       3.0   \n",
       "3         0.0      8.0  ...       0.0       0.0       0.0       7.0      13.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0       2.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1792      0.0      1.0  ...       0.0       0.0       0.0       2.0      14.0   \n",
       "1793      0.0      0.0  ...       0.0       0.0       0.0       6.0      16.0   \n",
       "1794      0.0      0.0  ...       0.0       0.0       0.0       2.0       9.0   \n",
       "1795      0.0      0.0  ...       0.0       0.0       0.0       5.0      12.0   \n",
       "1796      0.0      2.0  ...       0.0       0.0       1.0       8.0      12.0   \n",
       "\n",
       "      pixel_60  pixel_61  pixel_62  pixel_63  label  \n",
       "0         10.0       0.0       0.0       0.0      0  \n",
       "1         16.0      10.0       0.0       0.0      1  \n",
       "2         11.0      16.0       9.0       0.0      2  \n",
       "3         13.0       9.0       0.0       0.0      3  \n",
       "4         16.0       4.0       0.0       0.0      4  \n",
       "...        ...       ...       ...       ...    ...  \n",
       "1792      15.0       9.0       0.0       0.0      9  \n",
       "1793      14.0       6.0       0.0       0.0      0  \n",
       "1794      13.0       6.0       0.0       0.0      8  \n",
       "1795      16.0      12.0       0.0       0.0      9  \n",
       "1796      14.0      12.0       1.0       0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = load_digits()\n",
    "\n",
    "# Images are already flattened (8x8 image to 64 pixels)\n",
    "images = mnist.data\n",
    "\n",
    "# Create a DataFrame with image data as columns and labels as a separate column\n",
    "df = pd.DataFrame(data=images, columns=[f\"pixel_{i}\" for i in range(64)])\n",
    "df[\"label\"] = mnist.target\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "37275373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_54</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0         0.0      0.0      5.0     13.0      9.0      1.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0     12.0     13.0      5.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      4.0     15.0     12.0      0.0      0.0   \n",
       "3         0.0      0.0      7.0     15.0     13.0      1.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      1.0     11.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1792      0.0      0.0      4.0     10.0     13.0      6.0      0.0      0.0   \n",
       "1793      0.0      0.0      6.0     16.0     13.0     11.0      1.0      0.0   \n",
       "1794      0.0      0.0      1.0     11.0     15.0      1.0      0.0      0.0   \n",
       "1795      0.0      0.0      2.0     10.0      7.0      0.0      0.0      0.0   \n",
       "1796      0.0      0.0     10.0     14.0      8.0      1.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_54  pixel_55  pixel_56  pixel_57  pixel_58  \\\n",
       "0         0.0      0.0  ...       0.0       0.0       0.0       0.0       6.0   \n",
       "1         0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2         0.0      0.0  ...       5.0       0.0       0.0       0.0       0.0   \n",
       "3         0.0      8.0  ...       9.0       0.0       0.0       0.0       7.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1792      0.0      1.0  ...       4.0       0.0       0.0       0.0       2.0   \n",
       "1793      0.0      0.0  ...       1.0       0.0       0.0       0.0       6.0   \n",
       "1794      0.0      0.0  ...       0.0       0.0       0.0       0.0       2.0   \n",
       "1795      0.0      0.0  ...       2.0       0.0       0.0       0.0       5.0   \n",
       "1796      0.0      2.0  ...       8.0       0.0       0.0       1.0       8.0   \n",
       "\n",
       "      pixel_59  pixel_60  pixel_61  pixel_62  pixel_63  \n",
       "0         13.0      10.0       0.0       0.0       0.0  \n",
       "1         11.0      16.0      10.0       0.0       0.0  \n",
       "2          3.0      11.0      16.0       9.0       0.0  \n",
       "3         13.0      13.0       9.0       0.0       0.0  \n",
       "4          2.0      16.0       4.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1792      14.0      15.0       9.0       0.0       0.0  \n",
       "1793      16.0      14.0       6.0       0.0       0.0  \n",
       "1794       9.0      13.0       6.0       0.0       0.0  \n",
       "1795      12.0      16.0      12.0       0.0       0.0  \n",
       "1796      12.0      14.0      12.0       1.0       0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df['label']\n",
    "Y\n",
    "X = df.drop('label',axis= 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c763a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_54</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>993</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83</th>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>320</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>464</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>239</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1703</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>56</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>440</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>882</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>508</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "993       0.0      0.0      3.0     13.0     13.0      3.0      0.0      0.0   \n",
       "83        0.0      2.0     13.0     15.0     10.0      4.0      0.0      0.0   \n",
       "320       0.0      0.0      1.0     14.0      8.0      0.0      0.0      0.0   \n",
       "464       0.0      0.0      4.0     15.0     12.0      1.0      0.0      0.0   \n",
       "239       0.0      0.0      0.0      0.0     15.0      9.0      0.0      0.0   \n",
       "1703      0.0      0.0      4.0     14.0     11.0      3.0      0.0      0.0   \n",
       "56        0.0      0.0      0.0      0.0     12.0     13.0      1.0      0.0   \n",
       "440       0.0      0.0      7.0     13.0      2.0      0.0      0.0      0.0   \n",
       "882       0.0      0.0      1.0     12.0      8.0      0.0      0.0      0.0   \n",
       "508       0.0      0.0      6.0     10.0      9.0      4.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_54  pixel_55  pixel_56  pixel_57  pixel_58  \\\n",
       "993       0.0      0.0  ...      11.0       0.0       0.0       0.0       4.0   \n",
       "83        0.0      0.0  ...       0.0       0.0       0.0       2.0      12.0   \n",
       "320       0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "464       0.0      0.0  ...       2.0       0.0       0.0       0.0       7.0   \n",
       "239       0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "1703      0.0      0.0  ...       2.0       0.0       0.0       0.0       4.0   \n",
       "56        0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "440       0.0     11.0  ...       9.0       0.0       0.0       0.0       9.0   \n",
       "882       0.0      0.0  ...       8.0       0.0       0.0       0.0       1.0   \n",
       "508       0.0      0.0  ...       0.0       0.0       0.0       0.0       8.0   \n",
       "\n",
       "      pixel_59  pixel_60  pixel_61  pixel_62  pixel_63  \n",
       "993       10.0      16.0      16.0       4.0       0.0  \n",
       "83        14.0      11.0       1.0       0.0       0.0  \n",
       "320       13.0      14.0       0.0       0.0       0.0  \n",
       "464       13.0      12.0       2.0       0.0       0.0  \n",
       "239        1.0      15.0       5.0       0.0       0.0  \n",
       "1703      15.0      12.0       2.0       0.0       0.0  \n",
       "56         0.0      12.0      12.0       0.0       0.0  \n",
       "440       12.0       8.0      10.0      14.0       0.0  \n",
       "882       14.0      16.0      11.0       1.0       0.0  \n",
       "508       12.0       6.0       1.0       0.0       0.0  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "ae227cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0,1797,size=10)\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X.iloc[idx[i],:].values.reshape(8,8), cmap='gist_heat')\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    axes[i].set_title(str(int(Y[idx[i]])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98a24eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Train-Val Dataset Spliting.\n",
    "x_t,x_test,y_t,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 42)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_t,y_t,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b53868fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Dataset.\n",
    "normalizer = Normalizer()\n",
    "x_train = normalizer.fit_transform(x_train)\n",
    "x_val = normalizer.transform(x_val)\n",
    "x_test = normalizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3108c",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader class\n",
    "\n",
    "1. Basic Idea behind the Dataset and DataLoader class is to be decoupled from our model training code for better readability and modularity.\n",
    "2. PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data.\n",
    "3. Dataset class stores the samples and their corresponding labels, and DataLoader class wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efc39c",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "A custom Dataset class must implement three functions: ``__init__``, ``__len__``, and ``__getitem__``.\n",
    "\n",
    "1. The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms\n",
    "2. The __len__ function returns the number of samples in our dataset.\n",
    "3. The __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the sample and label and return it as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "398a2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,features,label):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.features[idx]\n",
    "        label = self.label.values[idx]\n",
    "        sample_tensor = torch.tensor(sample,dtype = torch.float32)\n",
    "        label_tensor = torch.tensor(label,dtype = torch.long)\n",
    "\n",
    "        return sample_tensor,label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2ad04258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "val_dataset = CustomDataset(x_val,y_val)\n",
    "test_dataset = CustomDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b3222dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "efbb5f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0113b07",
   "metadata": {},
   "source": [
    "## DataLoader Class\n",
    "\n",
    "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing(num_worker) to speed up data retrieval.\n",
    "\n",
    "`DataLoader is an iterable that abstracts this complexity for us in an easy API.`\n",
    "\n",
    "When we load the dataset into the DataLoader and we can iterate through the dataset as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "e3c9b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size = batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340088b",
   "metadata": {},
   "source": [
    "Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "a886e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.1720,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.0308, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.1199,  ..., 0.0171, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0000, 0.0178,  ..., 0.2666, 0.0178, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0145,  ..., 0.1161, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0142,  ..., 0.1275, 0.0142, 0.0000]])\n",
      "tensor([3, 8, 0, 7, 3, 0, 4, 8, 7, 7, 9, 4, 2, 8, 6, 5, 7, 4, 1, 8, 5, 3, 1, 3,\n",
      "        4, 0, 2, 1, 0, 0, 0, 5, 6, 8, 7, 3, 8, 5, 1, 1, 1, 4, 2, 3, 1, 4, 2, 2,\n",
      "        7, 1, 3, 9, 5, 8, 4, 8, 9, 6, 0, 2, 4, 0, 0, 6])\n"
     ]
    }
   ],
   "source": [
    "data,label = next(iter(train_dataloader))\n",
    "print(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fe71e",
   "metadata": {},
   "source": [
    "\n",
    "## `torch.nn.Module` and `torch.nn.Parameter`\n",
    "\n",
    "\n",
    "Except for `Parameter`, the classes we will be discussing are all subclasses of `torch.nn.Module`.\n",
    "\n",
    "`torch.nn.module` is the PyTorch base class which is meant to encapsulate behaviors specific to `PyTorch Models` and their `Components` like activation functions etc.\n",
    "\n",
    "One of the important behavior of `torch.nn.Module` is registering(Intializing) parameters for the layers defined using subclass of `Module`\n",
    "\n",
    "For Example:\n",
    "`Module` subclass ,`nn.Linear()` has learning weights, these weights are expressed as instances of `torch.nn.Parameter` class.\n",
    "\n",
    "The `Parameter` class is a subclass of `torch.Tensor`, with the special behavior that when they are assigned as attributes of a `Module`, they are added to the list of that modules parameters. These parameters can be accessed through the `parameters()` method on the `Module` class.\n",
    "\n",
    "As a simple example, we will be going to build a simple FFNN for MNIST Dataset for Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "5dd9c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    #STRUCTURE\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8*8, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    #DATA FLOW\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833970d4",
   "metadata": {},
   "source": [
    "## Using Functional Interface\n",
    "```\n",
    "1. It's a functional interface where we directly pass the input tensor to it and get the activated output.\n",
    "2. It does not hold or manage any internal state and therefore stateless.\n",
    "3. Since it's stateless, it's ideal when you don't need the module to track activations as part of the model's stateful components.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "cc11a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20dc8b",
   "metadata": {},
   "source": [
    "## Using nn.Sequential\n",
    "\n",
    "```\n",
    "1. This approach represent Model as a sequence of Operations.\n",
    "2. It the most concise way to define a model, but it offers less flexibility for models that require complex data flows or custom operations.\n",
    "3. \"nn.Sequential\" expects modules as its arguments.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d371c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "                                nn.Linear(64, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe620ff",
   "metadata": {},
   "source": [
    "## Using Batch Normalization and Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a17c2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64,512)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p = 0.2)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout_2 = nn.Dropout(p = 0.2)\n",
    "        self.fc3 = nn.Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.dropout_1(self.relu1(self.batch_norm1(self.fc1(x))))\n",
    "        x = self.dropout_2(self.relu2(self.batch_norm2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "b88896cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "00abb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "epochs = 100\n",
    "best_loss = 1e9\n",
    "patience = 5\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "74708afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: train_loss = 0.0008980 | val_loss = 0.0005383 \n",
      "Early Stopping !!!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()  # telling model to go to training mode\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    train_pred = 0\n",
    "    for data,label in train_dataloader:  #in each iteration data gets a batch from dataloader\n",
    "        data,label = data.to(device),label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_func(pred,label)\n",
    "        optimizer.zero_grad()  #clearing grad from prev batch\n",
    "        loss.backward()  #calc grad\n",
    "        optimizer.step() #update weights\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # pred.argmax(dim) -->gives index where the value is max accross col(if dim=0) or row(if dim=1)\n",
    "        train_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "        train_count += 1\n",
    "\n",
    "    train_loss = train_loss / train_count   # mean loss over all batches\n",
    "\n",
    "  # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()   # telling model to go to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_count = 0\n",
    "        val_pred = 0\n",
    "        for data,label in val_dataloader:\n",
    "            data,label = data.to(device),label.to(device)\n",
    "            pred = model(data)\n",
    "            loss = loss_func(pred,label)\n",
    "            val_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "            val_count += len(label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / val_count\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            count = 0\n",
    "            best_loss = val_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"mcheckpoint:{epoch+1}\")\n",
    "#             print(f\"mcheckpoint:{epoch+1}\")\n",
    "        else:\n",
    "            count += 1\n",
    "        if count == patience:\n",
    "            count=0\n",
    "            print(\"Early Stopping !!!\")\n",
    "            break\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"{epoch+1}: train_loss = {train_loss:.7f} | val_loss = {val_loss:.7f} \" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "7a1a8c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0006, Test Accuracy: 99.17%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model checkpoint\n",
    "# checkpoint_path = 'path_to_your_saved_checkpoint.pth'\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# # Assuming model and optimizer are defined elsewhere in your code\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load your test dataset\n",
    "# Assuming test_dataloader is defined elsewhere in your code and loaded with test data\n",
    "test_dataloader = test_dataloader\n",
    "\n",
    "# Initialize variables to monitor test performance\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# No gradient updates needed for testing\n",
    "with torch.no_grad():\n",
    "    for data, label in test_dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_func(pred, label)\n",
    "        test_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == label).sum().item()\n",
    "\n",
    "# Calculate average loss and accuracy over the test set\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "test_accuracy = 100. * correct / len(test_dataloader.dataset)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "2f952e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init.xavier_uniform_(layer1.weight)\n",
    "# def reinitialize_model(model):\n",
    "#     for layer in model.modules():\n",
    "#         if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#             # Reinitialize weights using an init function\n",
    "#             init.sparse_(layer.weight,sparsity = 0.1,std=0.01)\n",
    "\n",
    "#             # Reinitialize biases to zero (if biases exist)\n",
    "#             if layer.bias is not None:\n",
    "#                 init.zeros_(layer.bias)\n",
    "\n",
    "# # Apply the function to your model\n",
    "\n",
    "# reinitialize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "fce6ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  0\n",
      "prediction: 0\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2a532db1f30>"
      ]
     },
     "execution_count": 156,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = 30  #index\n",
    "test = torch.tensor(X.iloc[n,:],dtype = torch.float32).reshape(1,-1)\n",
    "print(\"actual: \",Y[n])\n",
    "with torch.no_grad():\n",
    "    pred = model(test)\n",
    "    \n",
    "print(\"prediction:\",pred.argmax(1).item())\n",
    "plt.imshow(X.iloc[n,:].values.reshape(8,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0a6e4aaf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
