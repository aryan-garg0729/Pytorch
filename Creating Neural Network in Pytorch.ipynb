{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "694d4bee",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.preprocessing import Normalizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "62ba93fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cdad571a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 65 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0         0.0      0.0      5.0     13.0      9.0      1.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0     12.0     13.0      5.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      4.0     15.0     12.0      0.0      0.0   \n",
       "3         0.0      0.0      7.0     15.0     13.0      1.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      1.0     11.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1792      0.0      0.0      4.0     10.0     13.0      6.0      0.0      0.0   \n",
       "1793      0.0      0.0      6.0     16.0     13.0     11.0      1.0      0.0   \n",
       "1794      0.0      0.0      1.0     11.0     15.0      1.0      0.0      0.0   \n",
       "1795      0.0      0.0      2.0     10.0      7.0      0.0      0.0      0.0   \n",
       "1796      0.0      0.0     10.0     14.0      8.0      1.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_55  pixel_56  pixel_57  pixel_58  pixel_59  \\\n",
       "0         0.0      0.0  ...       0.0       0.0       0.0       6.0      13.0   \n",
       "1         0.0      0.0  ...       0.0       0.0       0.0       0.0      11.0   \n",
       "2         0.0      0.0  ...       0.0       0.0       0.0       0.0       3.0   \n",
       "3         0.0      8.0  ...       0.0       0.0       0.0       7.0      13.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0       2.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1792      0.0      1.0  ...       0.0       0.0       0.0       2.0      14.0   \n",
       "1793      0.0      0.0  ...       0.0       0.0       0.0       6.0      16.0   \n",
       "1794      0.0      0.0  ...       0.0       0.0       0.0       2.0       9.0   \n",
       "1795      0.0      0.0  ...       0.0       0.0       0.0       5.0      12.0   \n",
       "1796      0.0      2.0  ...       0.0       0.0       1.0       8.0      12.0   \n",
       "\n",
       "      pixel_60  pixel_61  pixel_62  pixel_63  label  \n",
       "0         10.0       0.0       0.0       0.0      0  \n",
       "1         16.0      10.0       0.0       0.0      1  \n",
       "2         11.0      16.0       9.0       0.0      2  \n",
       "3         13.0       9.0       0.0       0.0      3  \n",
       "4         16.0       4.0       0.0       0.0      4  \n",
       "...        ...       ...       ...       ...    ...  \n",
       "1792      15.0       9.0       0.0       0.0      9  \n",
       "1793      14.0       6.0       0.0       0.0      0  \n",
       "1794      13.0       6.0       0.0       0.0      8  \n",
       "1795      16.0      12.0       0.0       0.0      9  \n",
       "1796      14.0      12.0       1.0       0.0      8  \n",
       "\n",
       "[1797 rows x 65 columns]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import load_digits\n",
    "\n",
    "# Load the MNIST dataset\n",
    "mnist = load_digits()\n",
    "\n",
    "# Images are already flattened (8x8 image to 64 pixels)\n",
    "images = mnist.data\n",
    "\n",
    "# Create a DataFrame with image data as columns and labels as a separate column\n",
    "df = pd.DataFrame(data=images, columns=[f\"pixel_{i}\" for i in range(64)])\n",
    "df[\"label\"] = mnist.target\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "37275373",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_54</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1792</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>...</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1793</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1794</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1795</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1796</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1797 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "0         0.0      0.0      5.0     13.0      9.0      1.0      0.0      0.0   \n",
       "1         0.0      0.0      0.0     12.0     13.0      5.0      0.0      0.0   \n",
       "2         0.0      0.0      0.0      4.0     15.0     12.0      0.0      0.0   \n",
       "3         0.0      0.0      7.0     15.0     13.0      1.0      0.0      0.0   \n",
       "4         0.0      0.0      0.0      1.0     11.0      0.0      0.0      0.0   \n",
       "...       ...      ...      ...      ...      ...      ...      ...      ...   \n",
       "1792      0.0      0.0      4.0     10.0     13.0      6.0      0.0      0.0   \n",
       "1793      0.0      0.0      6.0     16.0     13.0     11.0      1.0      0.0   \n",
       "1794      0.0      0.0      1.0     11.0     15.0      1.0      0.0      0.0   \n",
       "1795      0.0      0.0      2.0     10.0      7.0      0.0      0.0      0.0   \n",
       "1796      0.0      0.0     10.0     14.0      8.0      1.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_54  pixel_55  pixel_56  pixel_57  pixel_58  \\\n",
       "0         0.0      0.0  ...       0.0       0.0       0.0       0.0       6.0   \n",
       "1         0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "2         0.0      0.0  ...       5.0       0.0       0.0       0.0       0.0   \n",
       "3         0.0      8.0  ...       9.0       0.0       0.0       0.0       7.0   \n",
       "4         0.0      0.0  ...       0.0       0.0       0.0       0.0       0.0   \n",
       "...       ...      ...  ...       ...       ...       ...       ...       ...   \n",
       "1792      0.0      1.0  ...       4.0       0.0       0.0       0.0       2.0   \n",
       "1793      0.0      0.0  ...       1.0       0.0       0.0       0.0       6.0   \n",
       "1794      0.0      0.0  ...       0.0       0.0       0.0       0.0       2.0   \n",
       "1795      0.0      0.0  ...       2.0       0.0       0.0       0.0       5.0   \n",
       "1796      0.0      2.0  ...       8.0       0.0       0.0       1.0       8.0   \n",
       "\n",
       "      pixel_59  pixel_60  pixel_61  pixel_62  pixel_63  \n",
       "0         13.0      10.0       0.0       0.0       0.0  \n",
       "1         11.0      16.0      10.0       0.0       0.0  \n",
       "2          3.0      11.0      16.0       9.0       0.0  \n",
       "3         13.0      13.0       9.0       0.0       0.0  \n",
       "4          2.0      16.0       4.0       0.0       0.0  \n",
       "...        ...       ...       ...       ...       ...  \n",
       "1792      14.0      15.0       9.0       0.0       0.0  \n",
       "1793      16.0      14.0       6.0       0.0       0.0  \n",
       "1794       9.0      13.0       6.0       0.0       0.0  \n",
       "1795      12.0      16.0      12.0       0.0       0.0  \n",
       "1796      12.0      14.0      12.0       1.0       0.0  \n",
       "\n",
       "[1797 rows x 64 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y = df['label']\n",
    "Y\n",
    "X = df.drop('label',axis= 1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c763a024",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pixel_0</th>\n",
       "      <th>pixel_1</th>\n",
       "      <th>pixel_2</th>\n",
       "      <th>pixel_3</th>\n",
       "      <th>pixel_4</th>\n",
       "      <th>pixel_5</th>\n",
       "      <th>pixel_6</th>\n",
       "      <th>pixel_7</th>\n",
       "      <th>pixel_8</th>\n",
       "      <th>pixel_9</th>\n",
       "      <th>...</th>\n",
       "      <th>pixel_54</th>\n",
       "      <th>pixel_55</th>\n",
       "      <th>pixel_56</th>\n",
       "      <th>pixel_57</th>\n",
       "      <th>pixel_58</th>\n",
       "      <th>pixel_59</th>\n",
       "      <th>pixel_60</th>\n",
       "      <th>pixel_61</th>\n",
       "      <th>pixel_62</th>\n",
       "      <th>pixel_63</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>423</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>12.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1782</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>...</td>\n",
       "      <td>13.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>611</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>566</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>986</th>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>...</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>475</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>...</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1477</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>4.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>...</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>664</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>14.0</td>\n",
       "      <td>7.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1025</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>9.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>16.0</td>\n",
       "      <td>5.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>3.0</td>\n",
       "      <td>...</td>\n",
       "      <td>8.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.0</td>\n",
       "      <td>12.0</td>\n",
       "      <td>13.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1664</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2.0</td>\n",
       "      <td>10.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>15.0</td>\n",
       "      <td>6.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 64 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      pixel_0  pixel_1  pixel_2  pixel_3  pixel_4  pixel_5  pixel_6  pixel_7  \\\n",
       "423       0.0      0.0      9.0     16.0     11.0      1.0      0.0      0.0   \n",
       "1782      0.0      1.0     10.0     13.0      2.0      0.0      0.0      0.0   \n",
       "611       0.0      0.0      0.0     11.0     16.0      6.0      0.0      0.0   \n",
       "566       0.0      0.0      3.0     11.0     13.0      1.0      0.0      0.0   \n",
       "986       0.0      3.0     15.0     15.0      3.0      0.0      0.0      0.0   \n",
       "475       0.0      0.0      6.0     15.0     11.0      0.0      0.0      0.0   \n",
       "1477      0.0      1.0     11.0     16.0     16.0      4.0      0.0      0.0   \n",
       "664       0.0      0.0      5.0     12.0     16.0      7.0      0.0      0.0   \n",
       "1025      0.0      0.0      9.0     13.0     16.0      5.0      0.0      0.0   \n",
       "1664      0.0      0.0      2.0     10.0     11.0      1.0      0.0      0.0   \n",
       "\n",
       "      pixel_8  pixel_9  ...  pixel_54  pixel_55  pixel_56  pixel_57  pixel_58  \\\n",
       "423       0.0      5.0  ...      12.0       0.0       0.0       0.0      12.0   \n",
       "1782      0.0     10.0  ...      13.0       0.0       0.0       0.0       9.0   \n",
       "611       0.0      0.0  ...      10.0       0.0       0.0       0.0       0.0   \n",
       "566       0.0      6.0  ...       5.0       0.0       0.0       0.0       1.0   \n",
       "986       0.0      8.0  ...       5.0       0.0       0.0       5.0      16.0   \n",
       "475       0.0      6.0  ...       7.0       0.0       0.0       0.0       5.0   \n",
       "1477      0.0      7.0  ...       6.0       0.0       0.0       1.0      13.0   \n",
       "664       0.0      5.0  ...       0.0       0.0       0.0       0.0       5.0   \n",
       "1025      0.0      3.0  ...       8.0       0.0       0.0       0.0       8.0   \n",
       "1664      0.0      0.0  ...       0.0       0.0       0.0       0.0       1.0   \n",
       "\n",
       "      pixel_59  pixel_60  pixel_61  pixel_62  pixel_63  \n",
       "423       16.0      16.0      13.0       3.0       0.0  \n",
       "1782      13.0      11.0      10.0       9.0       0.0  \n",
       "611        9.0      16.0      16.0      10.0       0.0  \n",
       "566       14.0      13.0      12.0      15.0       5.0  \n",
       "986       16.0      16.0      16.0      16.0       0.0  \n",
       "475       16.0      15.0       9.0       0.0       0.0  \n",
       "1477      16.0      16.0      10.0       0.0       0.0  \n",
       "664       14.0      14.0       7.0       0.0       0.0  \n",
       "1025      12.0      13.0      15.0       2.0       0.0  \n",
       "1664      15.0       6.0       0.0       0.0       0.0  \n",
       "\n",
       "[10 rows x 64 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.sample(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ae227cb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 1200x500 with 10 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, axes = plt.subplots(2,5, figsize=(12,5))\n",
    "axes = axes.flatten()\n",
    "idx = np.random.randint(0,1797,size=10)\n",
    "for i in range(10):\n",
    "    axes[i].imshow(X.iloc[idx[i],:].values.reshape(8,8), cmap='gist_heat')\n",
    "    axes[i].axis('off') # hide the axes ticks\n",
    "    axes[i].set_title(str(int(Y[idx[i]])), color= 'black', fontsize=25)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "98a24eb5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Test-Train-Val Dataset Spliting.\n",
    "x_t,x_test,y_t,y_test = train_test_split(X,Y,test_size = 0.2,random_state = 42)\n",
    "x_train,x_val,y_train,y_val = train_test_split(x_t,y_t,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b53868fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Normalizing the Dataset.\n",
    "normalizer = Normalizer()\n",
    "x_train = normalizer.fit_transform(x_train)\n",
    "x_val = normalizer.transform(x_val)\n",
    "x_test = normalizer.transform(x_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33a3108c",
   "metadata": {},
   "source": [
    "## Dataset & Dataloader class\n",
    "\n",
    "1. Basic Idea behind the Dataset and DataLoader class is to be decoupled from our model training code for better readability and modularity.\n",
    "2. PyTorch provides two data primitives: `torch.utils.data.DataLoader` and `torch.utils.data.Dataset` that allow you to use pre-loaded datasets as well as your own data.\n",
    "3. Dataset class stores the samples and their corresponding labels, and DataLoader class wraps an iterable around the Dataset to enable easy access to the samples."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3efc39c",
   "metadata": {},
   "source": [
    "## Dataset Class\n",
    "\n",
    "A custom Dataset class must implement three functions: ``__init__``, ``__len__``, and ``__getitem__``.\n",
    "\n",
    "1. The __init__ function is run once when instantiating the Dataset object. We initialize the directory containing the images, the annotations file, and both transforms\n",
    "2. The __len__ function returns the number of samples in our dataset.\n",
    "3. The __getitem__ function loads and returns a sample from the dataset at the given index idx. Based on the index, it identifies the sample and label and return it as a tuple."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "398a2e40",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CustomDataset(Dataset):\n",
    "    def __init__(self,features,label):\n",
    "        self.features = features\n",
    "        self.label = label\n",
    "    \n",
    "    def __len__(self):\n",
    "        return self.features.shape[0]\n",
    "\n",
    "    def __getitem__(self,idx):\n",
    "        sample = self.features[idx]\n",
    "        label = self.label.values[idx]\n",
    "        sample_tensor = torch.tensor(sample,dtype = torch.float32)\n",
    "        label_tensor = torch.tensor(label,dtype = torch.long)\n",
    "\n",
    "        return sample_tensor,label_tensor"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "2ad04258",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = CustomDataset(x_train,y_train)\n",
    "val_dataset = CustomDataset(x_val,y_val)\n",
    "test_dataset = CustomDataset(x_test,y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "b3222dc0",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 64\n",
    "device = (\"cuda\" if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "efbb5f06",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cpu'"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0113b07",
   "metadata": {},
   "source": [
    "## DataLoader Class\n",
    "\n",
    "The Dataset retrieves our dataset’s features and labels one sample at a time. While training a model, we typically want to pass samples in “minibatches”, reshuffle the data at every epoch to reduce model overfitting, and use Python’s multiprocessing(num_worker) to speed up data retrieval.\n",
    "\n",
    "`DataLoader is an iterable that abstracts this complexity for us in an easy API.`\n",
    "\n",
    "When we load the dataset into the DataLoader and we can iterate through the dataset as needed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "e3c9b3c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataloader = DataLoader(train_dataset,batch_size=batch_size,shuffle=True)\n",
    "val_dataloader = DataLoader(val_dataset,batch_size = batch_size,shuffle=True)\n",
    "test_dataloader = DataLoader(test_dataset,batch_size=batch_size,shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7340088b",
   "metadata": {},
   "source": [
    "Each iteration below returns a batch of train_features and train_labels (containing batch_size=64 features and labels respectively). Because we specified shuffle=True, after we iterate over all batches the data is shuffled."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a886e8a9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.0000, 0.0000, 0.1817,  ..., 0.0000, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0637,  ..., 0.2228, 0.0159, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0145,  ..., 0.1161, 0.0000, 0.0000],\n",
      "        ...,\n",
      "        [0.0000, 0.0170, 0.2044,  ..., 0.1022, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1031, 0.0000, 0.0000],\n",
      "        [0.0000, 0.0000, 0.0000,  ..., 0.1907, 0.0587, 0.0000]])\n",
      "tensor([5, 9, 0, 0, 7, 8, 6, 0, 7, 0, 6, 7, 9, 7, 9, 1, 8, 9, 4, 8, 3, 4, 5, 4,\n",
      "        4, 6, 3, 4, 3, 9, 3, 4, 8, 6, 7, 3, 3, 6, 6, 0, 6, 4, 1, 7, 3, 7, 0, 5,\n",
      "        5, 3, 2, 8, 0, 7, 6, 5, 9, 9, 3, 5, 6, 3, 4, 8])\n"
     ]
    }
   ],
   "source": [
    "data,label = next(iter(train_dataloader))\n",
    "print(data)\n",
    "print(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d3fe71e",
   "metadata": {},
   "source": [
    "\n",
    "## `torch.nn.Module` and `torch.nn.Parameter`\n",
    "\n",
    "\n",
    "Except for `Parameter`, the classes we will be discussing are all subclasses of `torch.nn.Module`.\n",
    "\n",
    "`torch.nn.module` is the PyTorch base class which is meant to encapsulate behaviors specific to `PyTorch Models` and their `Components` like activation functions etc.\n",
    "\n",
    "One of the important behavior of `torch.nn.Module` is registering(Intializing) parameters for the layers defined using subclass of `Module`\n",
    "\n",
    "For Example:\n",
    "`Module` subclass ,`nn.Linear()` has learning weights, these weights are expressed as instances of `torch.nn.Parameter` class.\n",
    "\n",
    "The `Parameter` class is a subclass of `torch.Tensor`, with the special behavior that when they are assigned as attributes of a `Module`, they are added to the list of that modules parameters. These parameters can be accessed through the `parameters()` method on the `Module` class.\n",
    "\n",
    "As a simple example, we will be going to build a simple FFNN for MNIST Dataset for Digit Recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5dd9c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model1(nn.Module):\n",
    "    #STRUCTURE\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(8*8, 512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    #DATA FLOW\n",
    "    def forward(self, x):\n",
    "        x = self.relu1(self.fc1(x))\n",
    "        x = self.relu2(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "833970d4",
   "metadata": {},
   "source": [
    "## Using Functional Interface\n",
    "```\n",
    "1. It's a functional interface where we directly pass the input tensor to it and get the activated output.\n",
    "2. It does not hold or manage any internal state and therefore stateless.\n",
    "3. Since it's stateless, it's ideal when you don't need the module to track activations as part of the model's stateful components.\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "cc11a732",
   "metadata": {},
   "outputs": [],
   "source": [
    "class FunctionalModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64, 512)\n",
    "        self.fc2 = nn.Linear(512, 512)\n",
    "        self.fc3 = nn.Linear(512, 10)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = F.relu(self.fc2(x))\n",
    "        x = self.fc3(x)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2a20dc8b",
   "metadata": {},
   "source": [
    "## Using nn.Sequential\n",
    "\n",
    "```\n",
    "1. This approach represent Model as a sequence of Operations.\n",
    "2. It the most concise way to define a model, but it offers less flexibility for models that require complex data flows or custom operations.\n",
    "3. \"nn.Sequential\" expects modules as its arguments.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "d371c31c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SeqModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.layer = nn.Sequential(\n",
    "                                nn.Linear(64, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 512),\n",
    "                                nn.ReLU(),\n",
    "                                nn.Linear(512, 10))\n",
    "\n",
    "    def forward(self,x):\n",
    "        return self.layer(x)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8fe620ff",
   "metadata": {},
   "source": [
    "## Using Batch Normalization and Dropout Layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "a17c2268",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self):\n",
    "        super().__init__()\n",
    "        self.fc1 = nn.Linear(64,512)\n",
    "        self.batch_norm1 = nn.BatchNorm1d(512)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.dropout_1 = nn.Dropout(p = 0.2)\n",
    "        self.fc2 = nn.Linear(512,512)\n",
    "        self.batch_norm2 = nn.BatchNorm1d(512)\n",
    "        self.relu2 = nn.ReLU()\n",
    "        self.dropout_2 = nn.Dropout(p = 0.2)\n",
    "        self.fc3 = nn.Linear(512,10)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.dropout_1(self.relu1(self.batch_norm1(self.fc1(x))))\n",
    "        x = self.dropout_2(self.relu2(self.batch_norm2(self.fc2(x))))\n",
    "        x = self.fc3(x)\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b88896cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Model().to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "00abb4c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss_func = nn.CrossEntropyLoss()\n",
    "optimizer = torch.optim.Adam(model.parameters() , lr = 0.001)\n",
    "epochs = 100\n",
    "best_loss = 1e9\n",
    "patience = 5\n",
    "count=0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "74708afa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1: train_loss = 0.0036844 | val_loss = 0.0003080 \n",
      "Early Stopping !!!\n"
     ]
    }
   ],
   "source": [
    "for epoch in range(epochs):\n",
    "    \n",
    "    # Training\n",
    "    model.train()  # telling model to go to training mode\n",
    "    train_loss = 0\n",
    "    train_count = 0\n",
    "    train_pred = 0\n",
    "    for data,label in train_dataloader:  #in each iteration data gets a batch from dataloader\n",
    "        data,label = data.to(device),label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_func(pred,label)\n",
    "        optimizer.zero_grad()  #clearing grad from prev batch\n",
    "        loss.backward()  #calc grad\n",
    "        optimizer.step() #update weights\n",
    "        train_loss += loss.item()\n",
    "        \n",
    "        # pred.argmax(dim) -->gives index where the value is max accross col(if dim=0) or row(if dim=1)\n",
    "        train_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "        train_count += 1\n",
    "\n",
    "    train_loss = train_loss / train_count   # mean loss over all batches\n",
    "\n",
    "  # Validation\n",
    "    with torch.no_grad():\n",
    "        model.eval()   # telling model to go to evaluation mode\n",
    "        val_loss = 0\n",
    "        val_count = 0\n",
    "        val_pred = 0\n",
    "        for data,label in val_dataloader:\n",
    "            data,label = data.to(device),label.to(device)\n",
    "            pred = model(data)\n",
    "            loss = loss_func(pred,label)\n",
    "            val_pred += (pred.argmax(1) == label).sum().type(torch.float).item()\n",
    "            val_count += len(label)\n",
    "            val_loss += loss.item()\n",
    "\n",
    "        val_loss = val_loss / val_count\n",
    "\n",
    "        if val_loss < best_loss:\n",
    "            count = 0\n",
    "            best_loss = val_loss\n",
    "            checkpoint = {\n",
    "                'epoch': epoch + 1,\n",
    "                'model_state_dict': model.state_dict(),\n",
    "                'optimizer_state_dict': optimizer.state_dict(),\n",
    "                'loss': best_loss,\n",
    "            }\n",
    "            torch.save(checkpoint, f\"mcheckpoint:{epoch+1}\")\n",
    "#             print(f\"mcheckpoint:{epoch+1}\")\n",
    "        else:\n",
    "            count += 1\n",
    "        if count == patience:\n",
    "            count=0\n",
    "            print(\"Early Stopping !!!\")\n",
    "            break\n",
    "\n",
    "        if epoch%10 == 0:\n",
    "            print(f\"{epoch+1}: train_loss = {train_loss:.7f} | val_loss = {val_loss:.7f} \" )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "7a1a8c48",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Loss: 0.0006, Test Accuracy: 98.89%\n"
     ]
    }
   ],
   "source": [
    "# Load the saved model checkpoint\n",
    "# checkpoint_path = 'path_to_your_saved_checkpoint.pth'\n",
    "# checkpoint = torch.load(checkpoint_path)\n",
    "\n",
    "# # Assuming model and optimizer are defined elsewhere in your code\n",
    "# model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "# Put model in evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Load your test dataset\n",
    "# Assuming test_dataloader is defined elsewhere in your code and loaded with test data\n",
    "test_dataloader = test_dataloader\n",
    "\n",
    "# Initialize variables to monitor test performance\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "# No gradient updates needed for testing\n",
    "with torch.no_grad():\n",
    "    for data, label in test_dataloader:\n",
    "        data, label = data.to(device), label.to(device)\n",
    "        pred = model(data)\n",
    "        loss = loss_func(pred, label)\n",
    "        test_loss += loss.item()\n",
    "        correct += (pred.argmax(1) == label).sum().item()\n",
    "\n",
    "# Calculate average loss and accuracy over the test set\n",
    "test_loss /= len(test_dataloader.dataset)\n",
    "test_accuracy = 100. * correct / len(test_dataloader.dataset)\n",
    "\n",
    "print(f'Test Loss: {test_loss:.4f}, Test Accuracy: {test_accuracy:.2f}%')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "2f952e89",
   "metadata": {},
   "outputs": [],
   "source": [
    "# init.xavier_uniform_(layer1.weight)\n",
    "# def reinitialize_model(model):\n",
    "#     for layer in model.modules():\n",
    "#         if isinstance(layer, nn.Conv2d) or isinstance(layer, nn.Linear):\n",
    "#             # Reinitialize weights using an init function\n",
    "#             init.sparse_(layer.weight,sparsity = 0.1,std=0.01)\n",
    "\n",
    "#             # Reinitialize biases to zero (if biases exist)\n",
    "#             if layer.bias is not None:\n",
    "#                 init.zeros_(layer.bias)\n",
    "\n",
    "# # Apply the function to your model\n",
    "\n",
    "# reinitialize_model(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "fce6ca59",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "actual:  2\n",
      "prediction: 8\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x21128efb7f0>"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "n = np.random.randint(0,1000)  #index\n",
    "test = torch.tensor(X.iloc[n,:],dtype = torch.float32).reshape(1,-1)\n",
    "print(\"actual: \",Y[n])\n",
    "with torch.no_grad():\n",
    "    pred = model(test)\n",
    "    \n",
    "print(\"prediction:\",pred.argmax(1).item())\n",
    "plt.imshow(X.iloc[n,:].values.reshape(8,-1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "095cdec3",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e4b3264f",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
